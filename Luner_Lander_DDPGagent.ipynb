{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824616e-fe21-4de7-b824-57466f7b25fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 88.8     |\n",
      "|    ep_rew_mean     | -194     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 1262     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 355      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -192     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 1293     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 889      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=-305.50 +/- 98.81\n",
      "Episode length: 116.20 +/- 19.84\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 116      |\n",
      "|    mean_reward     | -306     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1000     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -201     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 708      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 1285     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 818      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1777     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=-250.06 +/- 133.04\n",
      "Episode length: 133.20 +/- 28.83\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 133      |\n",
      "|    mean_reward     | -250     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 561      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2256     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -210     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 594      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2638     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-179.36 +/- 203.28\n",
      "Episode length: 188.60 +/- 157.82\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 189      |\n",
      "|    mean_reward     | -179     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 3000     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -199     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 364      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 3150     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -208     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 399      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 3624     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-273.23 +/- 119.95\n",
      "Episode length: 196.80 +/- 82.34\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 197      |\n",
      "|    mean_reward     | -273     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 4000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 359      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 4129     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -216     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 388      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 4564     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-278.50 +/- 155.18\n",
      "Episode length: 138.00 +/- 30.90\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 138      |\n",
      "|    mean_reward     | -279     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 5000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -220     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 394      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 5156     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -219     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 419      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 5625     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-203.88 +/- 160.50\n",
      "Episode length: 135.20 +/- 38.33\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 135      |\n",
      "|    mean_reward     | -204     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 6000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -226     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 414      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 6121     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 114      |\n",
      "|    ep_rew_mean     | -228     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 437      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 6652     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=-207.01 +/- 75.13\n",
      "Episode length: 108.40 +/- 14.57\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 108      |\n",
      "|    mean_reward     | -207     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 7000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 114      |\n",
      "|    ep_rew_mean     | -224     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 440      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 7133     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 457      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 7556     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 473      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 7959     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-254.28 +/- 85.37\n",
      "Episode length: 112.80 +/- 17.23\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 113      |\n",
      "|    mean_reward     | -254     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 8000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -217     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 463      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 8392     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -209     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 477      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 8780     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-182.49 +/- 145.16\n",
      "Episode length: 349.00 +/- 329.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 349      |\n",
      "|    mean_reward     | -182     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 9000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 314      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 9245     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 324      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 9612     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-261.73 +/- 135.73\n",
      "Episode length: 190.20 +/- 75.07\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 190      |\n",
      "|    mean_reward     | -262     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 320      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 10083    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 333      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 10626    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=-237.36 +/- 128.55\n",
      "Episode length: 119.40 +/- 16.30\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 119      |\n",
      "|    mean_reward     | -237     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 11000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 338      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 11116    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -217     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 346      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 11492    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-264.66 +/- 184.25\n",
      "Episode length: 202.20 +/- 110.05\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 202      |\n",
      "|    mean_reward     | -265     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 12000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 338      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 12113    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 345      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 12504    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -216     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 353      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 12887    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=13000, episode_reward=-205.14 +/- 92.06\n",
      "Episode length: 125.00 +/- 17.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 125      |\n",
      "|    mean_reward     | -205     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 13000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 348      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 13312    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 348      |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 13737    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=-234.26 +/- 129.16\n",
      "Episode length: 114.20 +/- 15.41\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 114      |\n",
      "|    mean_reward     | -234     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 14000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 340      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 14117    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -216     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 346      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 14533    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -212     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 351      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 14932    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-251.25 +/- 117.96\n",
      "Episode length: 102.40 +/- 19.33\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 102      |\n",
      "|    mean_reward     | -251     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 15000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -210     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 352      |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 15458    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-249.40 +/- 95.51\n",
      "Episode length: 123.80 +/- 17.06\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 124      |\n",
      "|    mean_reward     | -249     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 16000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 358      |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 16174    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -210     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 363      |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 16661    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=17000, episode_reward=-247.35 +/- 121.82\n",
      "Episode length: 129.00 +/- 58.12\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 129      |\n",
      "|    mean_reward     | -247     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 17000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 360      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 17095    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 366      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 17523    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 373      |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 17935    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=-214.39 +/- 144.21\n",
      "Episode length: 108.20 +/- 9.91\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 108      |\n",
      "|    mean_reward     | -214     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 18000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 373      |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 18467    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -224     |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 378      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 18915    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=-304.38 +/- 40.53\n",
      "Episode length: 100.60 +/- 9.48\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 101      |\n",
      "|    mean_reward     | -304     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 19000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -225     |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 376      |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 19474    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -230     |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 380      |\n",
      "|    time_elapsed    | 52       |\n",
      "|    total_timesteps | 19979    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-283.56 +/- 11.38\n",
      "Episode length: 122.40 +/- 25.87\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 122      |\n",
      "|    mean_reward     | -284     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -234     |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 376      |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 20416    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -236     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 381      |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 20845    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=-221.11 +/- 113.75\n",
      "Episode length: 108.20 +/- 21.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 108      |\n",
      "|    mean_reward     | -221     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 21000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -235     |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 380      |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 21345    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -234     |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 384      |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 21801    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=-294.31 +/- 80.13\n",
      "Episode length: 135.40 +/- 44.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 135      |\n",
      "|    mean_reward     | -294     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 22000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -227     |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 381      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 22281    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -227     |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 385      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 22679    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=-226.57 +/- 61.13\n",
      "Episode length: 160.60 +/- 107.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 161      |\n",
      "|    mean_reward     | -227     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 23000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -226     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 381      |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 23143    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -229     |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 386      |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 23567    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-257.54 +/- 93.60\n",
      "Episode length: 108.00 +/- 15.06\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 108      |\n",
      "|    mean_reward     | -258     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 24000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -228     |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 389      |\n",
      "|    time_elapsed    | 61       |\n",
      "|    total_timesteps | 24144    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -222     |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 394      |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 24603    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-306.37 +/- 129.12\n",
      "Episode length: 164.00 +/- 81.03\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 164      |\n",
      "|    mean_reward     | -306     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 25000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -219     |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 390      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 25209    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -221     |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 395      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 25624    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -225     |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 398      |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 25944    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=26000, episode_reward=-191.58 +/- 101.88\n",
      "Episode length: 162.40 +/- 55.56\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 162      |\n",
      "|    mean_reward     | -192     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 26000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -228     |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 393      |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 26474    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -224     |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 397      |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 26992    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=27000, episode_reward=-302.68 +/- 42.31\n",
      "Episode length: 113.80 +/- 30.68\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 114      |\n",
      "|    mean_reward     | -303     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 27000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -223     |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 392      |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 27336    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -221     |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 395      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 27751    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=-250.34 +/- 136.35\n",
      "Episode length: 125.60 +/- 32.63\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 126      |\n",
      "|    mean_reward     | -250     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 28000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -217     |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 391      |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 28180    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 396      |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 28707    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=29000, episode_reward=-225.27 +/- 91.20\n",
      "Episode length: 134.20 +/- 64.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 134      |\n",
      "|    mean_reward     | -225     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 29000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -216     |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 392      |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 29207    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -217     |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 396      |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 29683    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-169.05 +/- 132.26\n",
      "Episode length: 118.40 +/- 17.12\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 118      |\n",
      "|    mean_reward     | -169     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 396      |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 30108    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 399      |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 30478    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -212     |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 403      |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 30883    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=31000, episode_reward=-266.97 +/- 74.16\n",
      "Episode length: 178.60 +/- 76.48\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 179      |\n",
      "|    mean_reward     | -267     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 31000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -207     |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 396      |\n",
      "|    time_elapsed    | 79       |\n",
      "|    total_timesteps | 31347    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -209     |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 399      |\n",
      "|    time_elapsed    | 79       |\n",
      "|    total_timesteps | 31759    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=-272.78 +/- 149.84\n",
      "Episode length: 188.80 +/- 82.78\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 189      |\n",
      "|    mean_reward     | -273     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 32000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -204     |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 391      |\n",
      "|    time_elapsed    | 82       |\n",
      "|    total_timesteps | 32285    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -203     |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 394      |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 32828    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=33000, episode_reward=-320.34 +/- 60.40\n",
      "Episode length: 164.80 +/- 37.08\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 165      |\n",
      "|    mean_reward     | -320     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 33000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -203     |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 388      |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 33303    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -207     |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 390      |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 33788    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=-287.51 +/- 49.29\n",
      "Episode length: 119.40 +/- 30.90\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 119      |\n",
      "|    mean_reward     | -288     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 34000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -206     |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 387      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 34326    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -210     |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 390      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 34670    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-334.75 +/- 142.08\n",
      "Episode length: 178.40 +/- 168.38\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 178      |\n",
      "|    mean_reward     | -335     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 35000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 380      |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 35211    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 382      |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 35563    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 385      |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 35959    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=-295.34 +/- 15.90\n",
      "Episode length: 131.20 +/- 30.27\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 131      |\n",
      "|    mean_reward     | -295     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 36000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 383      |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 36344    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -208     |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 385      |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 36709    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=37000, episode_reward=-274.02 +/- 66.49\n",
      "Episode length: 138.40 +/- 32.07\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 138      |\n",
      "|    mean_reward     | -274     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 37000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -210     |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 384      |\n",
      "|    time_elapsed    | 96       |\n",
      "|    total_timesteps | 37203    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -212     |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 387      |\n",
      "|    time_elapsed    | 97       |\n",
      "|    total_timesteps | 37656    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=38000, episode_reward=-213.88 +/- 90.68\n",
      "Episode length: 133.40 +/- 34.27\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 133      |\n",
      "|    mean_reward     | -214     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 38000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -217     |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 380      |\n",
      "|    time_elapsed    | 100      |\n",
      "|    total_timesteps | 38167    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -223     |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 382      |\n",
      "|    time_elapsed    | 100      |\n",
      "|    total_timesteps | 38630    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=39000, episode_reward=-249.77 +/- 121.09\n",
      "Episode length: 158.00 +/- 78.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 158      |\n",
      "|    mean_reward     | -250     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 39000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -222     |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 376      |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 39064    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -227     |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 377      |\n",
      "|    time_elapsed    | 104      |\n",
      "|    total_timesteps | 39486    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -227     |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 379      |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 39941    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-246.12 +/- 81.54\n",
      "Episode length: 113.00 +/- 35.49\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 113      |\n",
      "|    mean_reward     | -246     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -221     |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 370      |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 40351    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 371      |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 40748    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=41000, episode_reward=-334.62 +/- 72.51\n",
      "Episode length: 120.40 +/- 51.85\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 120      |\n",
      "|    mean_reward     | -335     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 41000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 365      |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 41318    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 367      |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 41844    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=-248.77 +/- 93.10\n",
      "Episode length: 135.00 +/- 31.58\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 135      |\n",
      "|    mean_reward     | -249     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 42000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 361      |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 42360    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 363      |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 42862    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=43000, episode_reward=-221.67 +/- 59.38\n",
      "Episode length: 209.60 +/- 202.56\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 210      |\n",
      "|    mean_reward     | -222     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 43000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 351      |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 43302    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 353      |\n",
      "|    time_elapsed    | 124      |\n",
      "|    total_timesteps | 43827    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=-224.25 +/- 149.30\n",
      "Episode length: 136.40 +/- 78.82\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 136      |\n",
      "|    mean_reward     | -224     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 44000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 352      |\n",
      "|    time_elapsed    | 125      |\n",
      "|    total_timesteps | 44412    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -222     |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 354      |\n",
      "|    time_elapsed    | 126      |\n",
      "|    total_timesteps | 44800    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-323.21 +/- 170.79\n",
      "Episode length: 157.20 +/- 52.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 157      |\n",
      "|    mean_reward     | -323     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 45000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 354      |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 45221    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -221     |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 356      |\n",
      "|    time_elapsed    | 128      |\n",
      "|    total_timesteps | 45627    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=-283.44 +/- 154.65\n",
      "Episode length: 118.00 +/- 22.10\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 118      |\n",
      "|    mean_reward     | -283     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 46000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -222     |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 356      |\n",
      "|    time_elapsed    | 129      |\n",
      "|    total_timesteps | 46106    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -221     |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 359      |\n",
      "|    time_elapsed    | 129      |\n",
      "|    total_timesteps | 46541    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -223     |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 361      |\n",
      "|    time_elapsed    | 129      |\n",
      "|    total_timesteps | 46977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=47000, episode_reward=-304.47 +/- 35.24\n",
      "Episode length: 130.20 +/- 28.25\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 130      |\n",
      "|    mean_reward     | -304     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 47000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -226     |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 361      |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 47488    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -233     |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 363      |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 47901    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=-281.50 +/- 124.85\n",
      "Episode length: 167.80 +/- 113.36\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 168      |\n",
      "|    mean_reward     | -281     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 48000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -231     |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 359      |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 48543    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -231     |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 361      |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 48975    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=49000, episode_reward=-193.59 +/- 129.97\n",
      "Episode length: 157.00 +/- 38.38\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 157      |\n",
      "|    mean_reward     | -194     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 49000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -227     |\n",
      "| time/              |          |\n",
      "|    episodes        | 428      |\n",
      "|    fps             | 359      |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 49515    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -227     |\n",
      "| time/              |          |\n",
      "|    episodes        | 432      |\n",
      "|    fps             | 360      |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 49845    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-228.38 +/- 134.12\n",
      "Episode length: 180.20 +/- 103.45\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 180      |\n",
      "|    mean_reward     | -228     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -224     |\n",
      "| time/              |          |\n",
      "|    episodes        | 436      |\n",
      "|    fps             | 346      |\n",
      "|    time_elapsed    | 145      |\n",
      "|    total_timesteps | 50520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.44     |\n",
      "|    critic_loss     | 73.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 211      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=51000, episode_reward=-517.31 +/- 157.30\n",
      "Episode length: 534.60 +/- 282.02\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 535      |\n",
      "|    mean_reward     | -517     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 51000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.14     |\n",
      "|    critic_loss     | 60.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 572      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 118      |\n",
      "|    ep_rew_mean     | -231     |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 253      |\n",
      "|    time_elapsed    | 205      |\n",
      "|    total_timesteps | 51948    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.68     |\n",
      "|    critic_loss     | 38.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1880     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=-262.33 +/- 172.23\n",
      "Episode length: 641.40 +/- 439.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 641      |\n",
      "|    mean_reward     | -262     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 52000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.66     |\n",
      "|    critic_loss     | 29.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2000     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=53000, episode_reward=-194.10 +/- 129.82\n",
      "Episode length: 835.20 +/- 329.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 835      |\n",
      "|    mean_reward     | -194     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 53000    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=-81.41 +/- 27.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -81.4    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 54000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.666   |\n",
      "|    critic_loss     | 24       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3629     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=55000, episode_reward=-74.28 +/- 13.93\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -74.3    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 55000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=56000, episode_reward=-122.44 +/- 151.05\n",
      "Episode length: 925.60 +/- 148.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 926      |\n",
      "|    mean_reward     | -122     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 56000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.82    |\n",
      "|    critic_loss     | 25.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5052     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 149      |\n",
      "|    ep_rew_mean     | -224     |\n",
      "| time/              |          |\n",
      "|    episodes        | 444      |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 416      |\n",
      "|    total_timesteps | 56000    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch as th\n",
    "import tensorflow as tf\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import EvalCallback, BaseCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "\n",
    "\n",
    "# Create the Lunar Lander environment\n",
    "env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "env = Monitor(env)\n",
    "# Define the action noise\n",
    "action_noise = NormalActionNoise(mean=0, sigma=th.ones(env.action_space.shape) * 0.1)\n",
    "\n",
    "# Define the DDPG agent\n",
    "model = DDPG(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    action_noise=action_noise,\n",
    "    verbose=1,\n",
    "    learning_rate=0.001,\n",
    "    buffer_size=50000,\n",
    "    batch_size=64,\n",
    "    learning_starts=50000,\n",
    "    gamma=0.99,\n",
    ")\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env=env,\n",
    "    best_model_save_path = \"C:\\\\Users\\\\Mac\\\\Desktop\\\\sems 10\\\\RL\\\\logs\",\n",
    "    log_path = \"C:\\\\Users\\\\Mac\\\\Desktop\\\\sems 10\\\\RL\\\\logs2\\\\logs23\",\n",
    "    #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_path),\n",
    "    eval_freq=1000,\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=250000, callback=eval_callback)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_path)\n",
    "# Load the training results from the callback\n",
    "x, y = ts2xy(load_results(\"C:\\\\Users\\\\Mac\\\\Desktop\\\\sems 10\\\\RL\\\\logs2\\\\logs23\"), \"timesteps\")\n",
    "\n",
    "# Print the mean reward values\n",
    "print(\"Mean rewards:\")\n",
    "for t, reward in zip(x, y):\n",
    "    print(f\"Timestep: {t}, Mean Reward: {reward}\")\n",
    "\n",
    "# Close the environments\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ef7f7-d311-4e18-b9fa-b67b04eb09bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
